{
 "cells": [
  {
   "cell_type": "raw",
   "id": "03d0bed3-8131-446e-ba8d-61a35fe127b6",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"CDSE Odata\"\n",
    "website: \n",
    "  page-navigation: true\n",
    "execute:\n",
    "  eval: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e897f1a2-d8f1-4afa-97ad-eaa04cdf55ff",
   "metadata": {},
   "source": [
    "Unfortunately, CDSE STAC doesn't work as well as it could (see: [https://github.com/Kayrros/sentinel-2-jp2-tlm](https://github.com/Kayrros/sentinel-2-jp2-tlm)). Luckily, OData can be used to get the data and process it, provided sufficient disk space is available and you know the tile identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c32614-6058-43d4-a0c3-eb09e7cab387",
   "metadata": {},
   "source": [
    "First step is to list all the available product names. `scripts/get_tile_list.py` handles this. \n",
    "\n",
    "```bash\n",
    "\n",
    "python src/get_tile_list.py -h\n",
    "\n",
    "usage: get_tile_list.py [-h] [--product_type PRODUCT_TYPE] [--cloud_cover CLOUD_COVER] [--outpath OUTPATH]\n",
    "                        tile_id start_date end_date\n",
    "\n",
    "positional arguments:\n",
    "  tile_id                      Tile id to query, for example 34VEM\n",
    "  start_date                   Start date for query, format yyyy-mm-dd\n",
    "  end_date                     End date for query, format yyyy-mm-dd\n",
    "\n",
    "options:\n",
    "  -h, --help                   show this help message and exit\n",
    "  --product_type PRODUCT_TYPE  Which product type to download (default: 1C)\n",
    "  --cloud_cover CLOUD_COVER    Maximum cloud cover percentage, default 20 (default: 20)\n",
    "  --outpath OUTPATH            Where to save the resulting product id list, default '.' (default: .)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf5426-c9fb-47a6-a97e-f05b46cb01ea",
   "metadata": {},
   "source": [
    "Downloading the data requires CDSE account, which can be created [here](https://documentation.dataspace.copernicus.eu/Registration.html). After this, `scripts/download_and_convert.py` can be used to bulk download the individual products and resample them to 10m resolution. Make sure to run with `--save_scl`, as it can be used for cloud and nodata masking.\n",
    "\n",
    "```bash\n",
    "\n",
    "usage: download_and_convert.py [-h] [--save_scl] product_name_file creds_file dl_path outpath\n",
    "\n",
    "Wrapper to both download and convert data with multiprocessing\n",
    "\n",
    "positional arguments:\n",
    "  product_name_file  Path to txt file containing the product ids\n",
    "  creds_file         Path to credential files\n",
    "  dl_path            tmp path to download to\n",
    "  outpath            Path to output mosaic folder\n",
    "\n",
    "options:\n",
    "  -h, --help         show this help message and exit\n",
    "  --save_scl         Whether to save SCL to mosaics (default: False)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07721fd-afda-46c7-ab20-2a2ef261d896",
   "metadata": {},
   "source": [
    "After all data has been downloaded, `scripts/make_cubes.py` creates monthly medians and saves them to `zarr` files, so that all data from one year is in a single file.\n",
    "\n",
    "```python\n",
    "    files = [f for f in os.listdir(datapath) if f.endswith('tif')]\n",
    "    arrays = []\n",
    "    dates = []\n",
    "    files.sort(key=lambda x: x.split('_')[2].split('T')[0])\n",
    "    for f in files: \n",
    "        date = f.split('_')[2].split('T')[0]\n",
    "        dates.append(pd.to_datetime(date))\n",
    "        da = rxr.open_rasterio(datapath/f, chunks={'x': 1024, 'y': 1024})\n",
    "        da = da.assign_coords(band=BAND_NAMES)\n",
    "        mask = da.sel(band='SCL')\n",
    "        da = da.where(~mask.isin([0,1,8,9,10]))\n",
    "        da = da.sel(band=da.band.values[:-1])\n",
    "        arrays.append(da)\n",
    "    cube = xr.concat(arrays, dim='time').assign_coords(time=dates)\n",
    "    cube = cube.chunk({'time': -1, 'band': -1, 'y': 1024, 'x': 1024})\n",
    "    monthly = cube.groupby('time.month').median(skipna=True)\n",
    "    monthly = monthly.to_dataset(dim='band')\n",
    "    monthly.to_zarr(outpath, mode='w')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6582c582-63aa-4f72-a4e3-d4fa81fea9bf",
   "metadata": {},
   "source": [
    "The full data processing chain can be done with this shell script:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "basepath=<set_your_own_datapath>\n",
    "\n",
    "tiles=(\"35WNT\")\n",
    "years=(\"2022\" \"2021\" \"2020\")\n",
    "mosaic_path=$basepath/s2-data/tiles\n",
    "median_path=$basepath/s2-data/medians\n",
    "\n",
    "for year in ${years[@]}; do\n",
    "    echo Processing year $year\n",
    "    mkdir $mosaic_path/$year\n",
    "    mkdir $median_path/$year\n",
    "    for tile in ${tiles[@]}; do    \n",
    "        mkdir $mosaic_path/$year/$tile\n",
    "        mkdir $median_path/$year/$tile\n",
    "        # Get file list for tile\n",
    "        python $basepath/src/get_tile_list.py $tile \\\n",
    "            ${year}-01-01 ${year}-12-31 \\\n",
    "            --cloud_cover 10 --product_type 2A \\\n",
    "            --outpath $mosaic_path/$year\n",
    "        python $basepath/src/download_and_convert.py \\\n",
    "               $mosaic_path/$year/${tile}_tileids.txt \\\n",
    "               $basepath/secret/creds.json \\\n",
    "               $basepath/s2-data/products \\\n",
    "               $mosaic_path/$year/$tile \\\n",
    "               --save_scl\n",
    "\n",
    "        echo Making monthly medians\n",
    "        \n",
    "        # Make monthly medians\n",
    "        python $basepath/src/make_cubes.py \\\n",
    "            $mosaic_path/$year/$tile \\\n",
    "            $median_path/$year/$tile.zarr\n",
    "\n",
    "    done\n",
    "done\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:presto]",
   "language": "python",
   "name": "conda-env-presto-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
